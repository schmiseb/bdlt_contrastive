{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd '/content/drive/MyDrive/Uni Leipzig/SS2022/bdlt_contrastive/dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import datasets\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def para(row, anchor_col=\"sentence1\", para_col=\"sentence2\", label_col=\"label\", path=\"paws\", name=\"small_diverse\", split=\"train\"):\n",
    "  out_row = {\n",
    "             \"sentence1\": row[anchor_col],\n",
    "             \"sentence2\": row[para_col],\n",
    "             \"label\": row[label_col],\n",
    "             \"path\": path,\n",
    "             \"name\": name,\n",
    "             \"split\": split}\n",
    "  return out_row\n",
    "\n",
    "dataset_definitions = [\n",
    "    {\"path\": \"paws\", \"name\": \"labeled_final\"},\n",
    "    {\"path\": \"paws\", \"name\": \"labeled_swap\"},\n",
    "    {\"path\": \"paws\", \"name\": \"unlabeled_final\"}]\n",
    "\n",
    "for definition in dataset_definitions:\n",
    "    # load max 50000 samples, only affects \"unlabeled_final\", all others are smaller\n",
    "    dataset = datasets.load_dataset(path=definition[\"path\"], name=definition[\"name\"]).filter(lambda example: example[\"id\"] <= 50000)\n",
    "    for split in [\"train\", \"validation\", \"test\"]:\n",
    "        out = []\n",
    "        if split not in dataset:\n",
    "            continue\n",
    "        dataset_part = pd.DataFrame(dataset[split])\n",
    "        #dataset_post = dataset_part.map(lambda x: para(model, tokenizer, x), num_proc=1)\n",
    "        for idx, row in dataset_part.iterrows():\n",
    "            out.append(para(row, split=split, path=definition[\"path\"], name=definition[\"name\"]))\n",
    "        df = pd.DataFrame(out)\n",
    "        #df = df[df[\"original_label\"] == 1]\n",
    "        df = df.reset_index()   \n",
    "        df.to_csv(f'raw/out_{definition[\"path\"]}_{definition[\"name\"]}_{split}.csv', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('bdlt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "93a0b903a60a7bb54103f7d1330837582c76a787345912a3be1026133156e7b1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
