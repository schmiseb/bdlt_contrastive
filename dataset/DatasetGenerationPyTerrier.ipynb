{"cells":[{"cell_type":"markdown","metadata":{"id":"J_V6G4LUhwrA"},"source":["# 1. Preparation\n","\n","\n","Execute the Notebooks\n","- prepareParaBank.ipynb\n","- prepareQuora.ipynb\n","- preparePAWS.ipynb\n","\n","before continuing here."]},{"cell_type":"markdown","metadata":{"id":"KSaEj8UXkjv8"},"source":["## 1.1 Mount drive"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Uu8RafSARvNO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661340464104,"user_tz":-120,"elapsed":17683,"user":{"displayName":"Jonas Probst","userId":"12529974203254550175"}},"outputId":"6f066b06-fce9-4ac1-e176-6979494cf499"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"pO9PjgdF-cXV"},"source":["## 1.2 Install necessary packages"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KlyQDWNmLcK1"},"outputs":[],"source":["%cd '/content/drive/MyDrive/Uni Leipzig/SS2022/bdlt_contrastive/dataset'"]},{"cell_type":"code","source":["!mkdir -p raw/quora raw/parabank neg indices"],"metadata":{"id":"QjrTWMCHQDDw"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NieqnymL1lv1"},"outputs":[],"source":["!pip install python-terrier"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p2avFSdSi-Aq"},"outputs":[],"source":["!pip install datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mroYf1gvLGmf"},"outputs":[],"source":["import re\n","import datasets\n","import os\n","import pyterrier as pt\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"fLHQ6XrxQBmn"},"source":["\n","## 1.3 Create Indices using PyTerrier and retrieve negatives"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fjax8DsENF96"},"outputs":[],"source":["if not pt.started():\n","  pt.init()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2O0Oe7gg1bo4"},"outputs":[],"source":["dataset_definitions = [\n","    {\"path\": \"parabank\", \"name\": \"small_diverse\"},\n","    {\"path\": \"paws\", \"name\": \"quora\"},\n","    {\"path\": \"paws\", \"name\": \"labeled_final\"},\n","    {\"path\": \"paws\", \"name\": \"labeled_swap\"},\n","    {\"path\": \"paws\", \"name\": \"unlabeled_final\"}\n","]\n","\n","max_res = 50\n","total_num_sentences = 6\n","for definition in dataset_definitions:\n","    dname = definition[\"name\"]\n","    dpath = definition[\"path\"]\n","    for split in [\"train\", \"validation\", \"test\"]:\n","        if not os.path.isfile(f\"raw/out_{dpath}_{dname}_{split}.csv\"):\n","            continue\n","        anchors_with_para = pd.read_csv(f\"raw/out_{dpath}_{dname}_{split}.csv\").fillna(\"\")\n","        \n","        if not os.path.isdir(f\"./indices/pd_index_{dpath}_{dname}_{split}\"):\n","            df = {\"docno\": [], \"text\": []}\n","            for index, row in anchors_with_para.iterrows():\n","                for sent in [\"sentence1\", \"sentence2\"]:\n","                    if sent and sent.strip() !=\"\" and sent != \"None\":\n","                        df[\"text\"].append(row[sent])\n","                        df[\"docno\"].append(str(index) + \"_\" + sent)\n","            df = pd.DataFrame.from_dict(df)\n","            # index the text, record the docnos as metadata\n","            pd_indexer = pt.DFIndexer(f\"./indices/pd_index_{dpath}_{dname}_{split}\")\n","            indexref = pd_indexer.index(df[\"text\"], df[\"docno\"])\n","            batch_ret = pt.BatchRetrieve(indexref,num_results=max_res)\n","        else:\n","            #pd_indexer = pt.DFIndexer(f\"./indices/pd_index_{dpath}_{dname}_{split}\")\n","            batch_ret = pt.BatchRetrieve(f\"./indices/pd_index_{dpath}_{dname}_{split}\",num_results=max_res)\n","\n","        \n","        if os.path.isfile(f\"neg/out_{dpath}_{dname}_{split}_processed.csv\"):\n","            continue\n","        \n","        out_list =  []\n","        paraphrases_only = anchors_with_para[anchors_with_para[\"label\"] == 1]\n","        for idx_row,row in paraphrases_only.iterrows():\n","            out_dict= {}\n","            for i in range(1, total_num_sentences+1):\n","                out_dict[f\"sentence{i}\"] = \"\"\n","            \n","            out_dict[\"sentence1\"] = row[\"sentence1\"]\n","            out_dict[\"sentence2\"] = row[\"sentence2\"]\n","\n","            s = re.sub(r'[^a-zA-Z0-9\\s]', ' ', row[\"sentence1\"])\n","\n","            res = batch_ret(s)\n","            score_prev = -1\n","            is_too_similar = True\n","            sen_num = 3\n","            used_idx_nums = []\n","            for _ ,r in res.iterrows():\n","                if is_too_similar:\n","                    if score_prev != -1 and r['score']/score_prev < 0.7:\n","                        is_too_similar = False\n","                    else:\n","                        score_prev = r['score']\n","                        continue\n","                idx_num, sent = r[\"docno\"].split(\"_\", 1)[0],  r[\"docno\"].split(\"_\", 1)[1]\n","\n","                # skip idx if it was already used, to make results more diverse\n","\n","                if idx_num not in used_idx_nums:\n","                    used_idx_nums.append(idx_num)\n","                    out_dict[f\"sentence{sen_num}\"] = anchors_with_para.loc[int(idx_num)][sent]\n","                else:\n","                    continue\n","                \n","                # break if enough negatives are collected\n","                if sen_num == total_num_sentences:\n","                    break\n","                sen_num += 1\n","\n","            all_sentences_valid = True\n","            for key, value in out_dict.items():\n","                if value == \"\":\n","                    all_sentences_valid = False\n","            \n","            if all_sentences_valid:\n","                out_list.append(out_dict)\n","                    \n","\n","        out_df = pd.DataFrame(out_list)\n","\n","        out_df.to_csv(f\"neg/out_{dpath}_{dname}_{split}_processed.csv\", index_label=\"idx\")"]},{"cell_type":"markdown","metadata":{"id":"3_qKa9DIQBmp"},"source":["## Combine all created csvs to one Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qJQNPsTNuplU"},"outputs":[],"source":["from glob import glob\n","\n","data_dir = \"../dataset/neg/\"\n","train_csvs = glob(data_dir + \"*train*.csv\")\n","test_csvs = glob(data_dir + \"*test*.csv\")\n","validation_csvs = glob(data_dir + \"*validation*.csv\")\n","\n","dataset = datasets.load_dataset(\"csv\", name=\"contrastive_paws_parabank\", data_files={\n","    \"train\": train_csvs,\n","    \"test\": test_csvs,\n","    \"validation\": validation_csvs})\n"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"DatasetGenerationPyTerrier.ipynb","provenance":[{"file_id":"1TPN3UvQsfE01W15ciYYwKjMe3gIqx-V-","timestamp":1660242121140},{"file_id":"113d6cexawrKtOsTdj5PqdewcSw-RjcOr","timestamp":1659969466566}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.8.13 ('bdlt')","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.13"},"vscode":{"interpreter":{"hash":"93a0b903a60a7bb54103f7d1330837582c76a787345912a3be1026133156e7b1"}}},"nbformat":4,"nbformat_minor":0}